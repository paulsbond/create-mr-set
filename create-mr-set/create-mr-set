#!/usr/bin/env python3

import argparse
import Bio.Seq
import Bio.SeqIO
import Bio.SeqRecord
import datetime
import gzip
import multiprocessing
import os
import random
import rcsb
import seqtools
import sys
import tasks
import urllib.request
import utils
import xml.etree.ElementTree as ET

## ARGUMENTS

def add_required_arguments(parser):
  required = parser.add_argument_group("Required arguments")
  required.add_argument("--pdb-coords", metavar="DIR", required=True, help="Directory containing divided coordinate files in gzipped PDB format (??/pdb????.ent.gz)")
  required.add_argument("--pdb-sfs", metavar="DIR", required=True, help="Directory containing divided reflection data files in gzipped CIF format (??/r????sf.ent.gz)")
  required.add_argument("--pdb-reports", metavar="DIR", required=True, help="Directory containing divided validation reports in gzipped XML format (??/????/????_validation.xml.gz)")

def add_optional_arguments(parser):
  optional = parser.add_argument_group("Optional arguments")
  optional.add_argument("--help", action="help", help="Show this help message and exit")
  optional.add_argument("--jobs", metavar="N", default="auto", help="Number of CPU threads to use (default: auto)")
  optional.add_argument("--model-model-rmsd", type=float, metavar="X", default=1.5, help="Minimum RMSD between two models (default: 1.5)")
  optional.add_argument("--model-model-seqid", type=int, metavar="[95,90,70,50,40,30]", choices=[95,90,70,50,40,30], default=95, help="Maximum sequence identity between two models (default: 95)")
  optional.add_argument("--model-target-qscore", type=float, metavar="X", default=0.1, help="Minimum GESAMT Q-score between model and target (default: 0.1)")
  optional.add_argument("--model-target-rmsd", type=float, metavar="X", default=3.0, help="Maximum RMSD between model and target (default: 3.0)")
  optional.add_argument("--model-target-seqid", type=int, metavar="[95,90,70,50,40,30]", choices=[95,90,70,50,40,30], default=95, help="Maximum sequence identity between model and target (default: 95)")
  optional.add_argument("--num-models", type=int, metavar="N", default=10, help="Maximum number of models to choose for each unique chain (default: 10)")
  optional.add_argument("--num-structures", type=int, metavar="N", default=2, help="Maximum number of structures to find in each resolution bin (default: 200)") # TODO: Change back to default
  optional.add_argument("--res-bins", type=int, metavar="N", default=2, help="Number of resolution bins (default: 10)") # TODO: Change back to default
  optional.add_argument("--res-max", type=float, metavar="X", default=3.0, help="Maximum resolution (exclusive) (default: 3.5)")  # TODO: Change back to default
  optional.add_argument("--res-min", type=float, metavar="X", default=1.0, help="Minimum resolution (inclusive) (default: 1.0)")
  optional.add_argument("--structure-seqid", type=int, metavar="[95,90,70,50,40,30]", choices=[95,90,70,50,40,30], default=50, help="Maximum sequence identity used for filtering structures with similar chains (default: 50)")
  optional.add_argument("--validation-clash", type=int, metavar="N", default=40, help="Clashscore percentile threshold (default: 40)")
  optional.add_argument("--validation-rama", type=int, metavar="N", default=40, help="Percentage Ramachandran outliers percentile threshold (default: 40)")
  optional.add_argument("--validation-rfree", type=int, metavar="N", default=50, help="Rfree percentile threshold (default: 50)")
  optional.add_argument("--validation-rota", type=int, metavar="N", default=40, help="Percentage rotamer outliers percentile threshold (default: 40)")
  optional.add_argument("--validation-rsrz", type=int, metavar="N", default=40, help="Percentage RSRZ outliers percentile threshold (default: 40)")

def add_calculated_arguments(args):
  args.res_step = (args.res_max - args.res_min) / args.res_bins
  args.jobs = os.cpu_count() if args.jobs == "auto" else int(args.jobs)
  args.jobs = max(1, min(args.jobs, os.cpu_count()))

def parse_args():
  description = "Creates a new molecular replacement test set."
  parser = argparse.ArgumentParser(description=description, add_help=False)
  add_required_arguments(parser)
  add_optional_arguments(parser)
  args = parser.parse_args()
  for arg in sorted(vars(args)):
    user_arg = "--%s" % arg.replace("_", "-")
    print("%-21s  %s" % (user_arg, getattr(args, arg)))
  print("")
  add_calculated_arguments(args)
  return args

## GET STRUCTURES

def get_structures():
  print("## GETTING A LIST OF X-RAY PROTEIN STRUCTURES ##\n")
  structures = rcsb.structures()
  print("")
  return structures

## CHOOSE STRUCTURES

class ResolutionBin:
  def __init__(self, i):
    self.min_res = args.res_min + i * args.res_step
    self.max_res = args.res_min + (i + 1) * args.res_step
    self.structures = []
    self.chosen = []

def assign_resolution_bins(structures):
  bins = [ResolutionBin(i) for i in range(args.res_bins)]
  for structure in list(structures.values()):
    if (structure.resolution < args.res_min or
        structure.resolution >= args.res_max):
      continue
    i = int((structure.resolution - args.res_min) / args.res_step)
    bins[i].structures.append(structure)
  return bins

def input_files_exist(structure):
  pdb = structure.id.lower()
  structure.paths = {
    "gzipped_pdb_coords": os.path.join(args.pdb_coords, pdb[1:3], "pdb%s.ent.gz" % pdb),
    "gzipped_pdb_sfs": os.path.join(args.pdb_sfs, pdb[1:3], "r%ssf.ent.gz" % pdb),
    "gzipped_pdb_report": os.path.join(args.pdb_reports, pdb[1:3], pdb, "%s_validation.xml.gz" % pdb),
  }
  return all(os.path.exists(p) for p in structure.paths.values())

def validation_report_okay(structure):
  attrib_key_dict = {
    "relative-percentile-DCC_Rfree": "validation_clash",
    "relative-percentile-clashscore": "validation_rama",
    "relative-percentile-percent-RSRZ-outliers": "validation_rfree",
    "relative-percentile-percent-rama-outliers": "validation_rota",
    "relative-percentile-percent-rota-outliers": "validation_rsrz",
  }
  path = structure.paths["gzipped_pdb_report"]
  if not os.path.exists(path): return False
  with gzip.open(path) as f:
    content = f.read()
  attribs = ET.fromstring(content).find("Entry").attrib
  for attrib in attrib_key_dict:
    key = attrib_key_dict[attrib]
    if attrib not in attribs: return False
    percentile = float(attribs[attrib])
    threshold = getattr(args, key)
    if percentile < threshold: return False
    setattr(structure, key, percentile)
  return True

def choose_structures(structures):
  print("## CHOOSING STRUCTURES ##\n")
  res_bins = assign_resolution_bins(structures)
  chosen_clusters = set()
  cluster_attr = "cluster%d" % args.structure_seqid
  res_bins.sort(key=lambda res_bin: len(res_bin.structures))
  for res_bin in res_bins:
    title = "Choosing %.2f-%.2fA structures (%d to choose from)" % (
      res_bin.min_res, res_bin.max_res, len(res_bin.structures))
    progress_bar = utils.ProgressBar(title, args.num_structures)
    random.shuffle(res_bin.structures)
    num_checked = 0
    num_missing_files = 0
    num_too_similar = 0
    num_failed_validation = 0
    for structure in res_bin.structures:
      passed = True
      num_checked += 1
      if not input_files_exist(structure):
        num_missing_files += 1
        passed = False
      clusters = {getattr(c, cluster_attr) for c in structure.chains.values()}
      if any(c in chosen_clusters for c in clusters):
        num_too_similar += 1
        passed = False
      if not validation_report_okay(structure):
        num_failed_validation += 1
        passed = False
      if passed:
        res_bin.chosen.append(structure)
        chosen_clusters.update(clusters)
        progress_bar.increment()
        if len(res_bin.chosen) == args.num_structures:
          break
    progress_bar.finish()
    print("Total number checked:          %6d" % num_checked)
    print("Missing input files:           %6d" % num_missing_files)
    print("Too similar to already chosen: %6d" % num_too_similar)
    print("Failed validation checks:      %6d" % num_failed_validation)
    print("")
  chosen = {s.id: s for r in res_bins for s in r.chosen}
  if len(chosen) < 1:
    sys.exit("ERROR: No structures chosen")
  for s in chosen.values():
    os.mkdir(s.id)
  return chosen

## GET SEQUENCES

def download_sequences(structures):
  print("Downloading sequences ...")
  ids = [s.id for s in structures.values()]
  url = "https://www.rcsb.org/pdb/download/downloadFastaFiles.do"
  url += "?structureIdList=%s" % ",".join(ids)
  url += "&compressionType=uncompressed"
  urllib.request.urlretrieve(url, "sequences.fasta")

def extract_sequences(structures):
  print("Extracting sequences ...")
  for record in Bio.SeqIO.parse("sequences.fasta", "fasta"):
    structureId = record.id[:4]
    chainId = record.id[5:6]
    if structureId in structures:
      structure = structures[structureId]
      if chainId in structure.chains:
        chain = structure.chains[chainId]
        chain.seq = str(record.seq)

def write_sequence(structure, name, path):
  records = []
  for chainId in structure.chains:
    chain = structure.chains[chainId]
    record = Bio.SeqRecord.SeqRecord(Bio.Seq.Seq(chain.seq),
      id="%s:%s" % (structure.id, chainId), description="")
    records.append(record)
  structure.paths[name] = path
  Bio.SeqIO.write(records, path, "fasta")
  return structure

def write_deposited_sequence(structure):
  path = os.path.join(structure.id, "%s.fasta" % structure.id)
  structure = write_sequence(structure, "deposited_seq", path)
  return structure

def remove_duplicate_chains(structure):
  seq_chain_dict = {}
  for chainId in sorted(structure.chains):
    chain = structure.chains[chainId]
    if chain.seq not in seq_chain_dict:
      chain.copies = 1
      seq_chain_dict[chain.seq] = chain
    else:
      seq_chain_dict[chain.seq].copies += 1
      del structure.chains[chainId]
  return structure

def write_unique_sequence(structure):
  path = os.path.join(structure.id, "unique.fasta")
  structure = write_sequence(structure, "unique_seq", path)
  return structure

def add_chains_metadata(structure):
  chains = {}
  for chainId in sorted(structure.chains):
    chain = structure.chains[chainId]
    chains[chainId] = {
      "length": len(chain.seq),
      "copies": chain.copies
    }
  structure.add_metadata("chains", chains)
  return structure

def get_sequences(structures):
  print("## GETTING FULL SEQUENCES ##\n")
  download_sequences(structures)
  extract_sequences(structures)
  utils.parallel("Writing deposited sequences", write_deposited_sequence, structures, args.jobs)
  utils.parallel("Removing duplicate chains", remove_duplicate_chains, structures, args.jobs)
  utils.parallel("Writing unique sequences", write_unique_sequence, structures, args.jobs)
  utils.parallel("Writing metadata", add_chains_metadata, structures, args.jobs)
  print("")

## PREPARE STRUCTURE DATA ##

def unzip_input_files(structure):
  structure.paths["deposited_pdb"] = os.path.join(structure.id, "%s.pdb" % structure.id)
  structure.paths["deposited_cif"] = os.path.join(structure.id, "%s-sf.cif" % structure.id)
  utils.run("gunzip", ["-c", structure.paths["gzipped_pdb_coords"]], stdout=structure.paths["deposited_pdb"])
  utils.run("gunzip", ["-c", structure.paths["gzipped_pdb_sfs"]], stdout=structure.paths["deposited_cif"])
  return structure

def convert_to_mtz(structure):
  prefix = os.path.join(structure.id, "cif2mtz")
  result = tasks.cif2mtz(structure.paths["deposited_cif"], prefix)
  if "error" in result:
    structure.add_metadata("error", result["error"])
  else:
    structure.hkl = result["hklout"]
  return structure

def convert_amplitudes(structure):
  prefix = os.path.join(structure.id, "ctruncate")
  result = tasks.convert_amplitudes(structure.hkl, structure.paths["deposited_seq"], prefix)
  if "error" in result:
    structure.add_metadata("error", result["error"])
  else:
    structure.hkl = result["hklout"]
  return structure

def prepare_structure_data(structures):
  print("## PREPARING STRUCTURE DATA ##\n")
  utils.parallel("Unzipping input files", unzip_input_files, structures, args.jobs)
  utils.parallel("Converting to MTZ", convert_to_mtz, structures, args.jobs)
  utils.remove_errors(structures)
  utils.parallel("Converting amplitudes", convert_amplitudes, structures, args.jobs)
  #convert_amplitudes(list(structures.values())[0])
  print("")

## MAIN

if __name__ == "__main__":
  print("###################")
  print("## Create MR Set ##")
  print("###################")
  print("")
  print("Please cite:")
  print("XXXX")
  print("")
  print("Time: %s\n" % datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

  if "CCP4" not in os.environ:
    sys.exit("Please setup the CCP4 environment")

  args = parse_args()
  structures = get_structures()
  chosen = choose_structures(structures)
  get_sequences(chosen)
  prepare_structure_data(chosen)

  print("------------------")
  print("Normal termination")
  print("------------------")
